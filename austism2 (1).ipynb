{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Imports and Model Initialization\n",
        "\n",
        "1.YOLOv8 Model Loading:\n",
        "\n",
        "The YOLO model is initialized by specifying the path to the trained model weights (terapistchildbestwright.pt), which is assumed to have been trained to detect \"Child\" and \"Therapist.\"\n",
        "\n",
        "2.Re-identification (Re-ID) Model Loading:\n",
        "\n",
        "OSNet (osnet_x0_25) is loaded for appearance-based person re-identification. It extracts embeddings from person images that help track them over time.\n",
        "\n",
        "3.DeepSORT Tracker Initialization:\n",
        "\n",
        "A DeepSort tracker is initialized to track objects based on motion and appearance embeddings."
      ],
      "metadata": {
        "id": "6p3Etwj3prkZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Index\n",
        "\n",
        "1.Imports and Dependencies\n",
        "\n",
        "Importing Libraries\n",
        "\n",
        "cv2\n",
        "\n",
        "cv2_imshow from Google Colab\n",
        "\n",
        "DeepSort from deep_sort_realtime\n",
        "\n",
        "YOLO from ultralytics\n",
        "\n",
        "torch\n",
        "\n",
        "torchreid\n",
        "\n",
        "numpy\n",
        "\n",
        "2.Model Initialization\n",
        "\n",
        "Loading YOLOv8 Model\n",
        "\n",
        "Loading Re-identification Model (OSNet)\n",
        "\n",
        "Moving Re-identification Model to GPU\n",
        "\n",
        "3.Tracker Initialization\n",
        "\n",
        "Configuring DeepSORT Tracker\n",
        "4.Unique ID Management\n",
        "\n",
        "Initializing Counters for Unique IDs\n",
        "\n",
        "Creating ID Map for Tracks\n",
        "\n",
        "5.video Processing Setup\n",
        "\n",
        "Loading Video File\n",
        "\n",
        "Setting Up Video Writer for Output\n",
        "\n",
        "6.Main Processing Loop\n",
        "\n",
        "Reading Frames from Video\n",
        "\n",
        "YOLOv8 Object Detection\n",
        "\n",
        "Extracting Bounding Boxes and Features\n",
        "Extracting Appearance Features using Re-identification Model\n",
        "\n",
        "Updating Tracker with Detections and Features\n",
        "\n",
        "Drawing Bounding Boxes and IDs on Frames\n",
        "\n",
        "Assigning Unique IDs to Tracks\n",
        "Labeling Objects in Frames\n",
        "Writing Processed Frame to Output Video\n",
        "\n",
        "Displaying Frame in Notebook\n",
        "\n",
        "7.Cleanup\n",
        "\n",
        "Releasing Video Capture and Writer\n",
        "\n",
        "Closing OpenCV Windows"
      ],
      "metadata": {
        "id": "4K9j-vJHp01R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9RSZoWnGHox",
        "outputId": "7a282072-e4fc-4741-a0dd-f8d20198af24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.87-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.19.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.6-py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Downloading ultralytics-8.2.87-py3-none-any.whl (872 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m872.1/872.1 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.6-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.2.87 ultralytics-thop-2.0.6\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjtVLYmNGMTh",
        "outputId": "5e6e374e-8eda-448e-8cf7-1b8ae66743ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.2.87)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.19.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1xpb1xiGMWf",
        "outputId": "060aabc7-196a-4fdd-b104-4f849bddd867"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deep-sort-realtime\n",
            "  Downloading deep_sort_realtime-1.3.2-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deep-sort-realtime) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from deep-sort-realtime) (1.13.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from deep-sort-realtime) (4.10.0.84)\n",
            "Downloading deep_sort_realtime-1.3.2-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: deep-sort-realtime\n",
            "Successfully installed deep-sort-realtime-1.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install deep-sort-realtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwqLlVdhWyi8",
        "outputId": "a51a92a7-4cbc-4d98-d3c2-cc7ff193ab8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchreid\n",
            "  Downloading torchreid-0.2.5.tar.gz (92 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/92.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.7/92.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: torchreid\n",
            "  Building wheel for torchreid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchreid: filename=torchreid-0.2.5-py3-none-any.whl size=144325 sha256=7ef32b44512e5646959fd05eb6d3d24c850bb7d2c57dd5127149d11e7ace0b5e\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/2d/36/816a48465cefd3e58be0317648a4c52ce39ae817f935212099\n",
            "Successfully built torchreid\n",
            "Installing collected packages: torchreid\n",
            "Successfully installed torchreid-0.2.5\n"
          ]
        }
      ],
      "source": [
        "!pip install torchreid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4DugFFXGMZX",
        "outputId": "0226df2f-faaf-46de-eaeb-083cdcb464c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "import torchreid\n",
        "import numpy as np\n",
        "\n",
        "# Load the YOLOv8 model\n",
        "model = YOLO('/content/drive/MyDrive/terapistchildbestwright.pt')\n",
        "\n",
        "# Load the re-identification model (OSNet)\n",
        "reid_model = torchreid.models.build_model(name='osnet_x0_25', num_classes=1000, pretrained=True)\n",
        "reid_model.eval()\n",
        "\n",
        "# Move the re-identification model to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "reid_model.to(device)\n",
        "\n",
        "# Initialize DeepSORT Tracker\n",
        "tracker = DeepSort(max_age=30, nn_budget=70, max_iou_distance=0.7, n_init=3)\n",
        "\n",
        "# Unique ID management for children and therapists\n",
        "child_unique_id = 1\n",
        "therapist_unique_id = 1\n",
        "id_map = {}  # Maps track_id to (unique_id, class)\n",
        "\n",
        "# Load the video\n",
        "cap = cv2.VideoCapture('/content/drive/MyDrive/autism2.mp4')\n",
        "\n",
        "# Get video writer to save the output video\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter('output_video.mp4', fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # YOLOv8 detection\n",
        "    results = model(frame)\n",
        "    detections = results[0].boxes\n",
        "\n",
        "    # Convert detections to DeepSORT format\n",
        "    boxes = []\n",
        "    features = []\n",
        "    for box in detections:\n",
        "        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)\n",
        "        width = x2 - x1\n",
        "        height = y2 - y1\n",
        "        conf = box.conf[0]\n",
        "        cls = int(box.cls[0])\n",
        "        if cls in [0, 1]:  # 0 = Child, 1 = Therapist in your trained model\n",
        "            # Correct format for DeepSORT: [[x1, y1, width, height], confidence]\n",
        "            boxes.append([[x1, y1, width, height], conf.item()])\n",
        "\n",
        "            # Extract appearance embeddings using the re-identification model\n",
        "            crop = frame[y1:y2, x1:x2]\n",
        "            crop = cv2.resize(crop, (128, 256))  # Resize as per the model's input size\n",
        "            crop = torch.tensor(crop).permute(2, 0, 1).float().unsqueeze(0).to(device) / 255.0  # Prepare the image tensor\n",
        "            with torch.no_grad():\n",
        "                feature = reid_model(crop).cpu().numpy().flatten()  # Flatten to ensure proper shape\n",
        "            features.append(feature)\n",
        "\n",
        "    # Ensure boxes and features align\n",
        "    assert len(boxes) == len(features), \"Mismatch between number of boxes and features.\"\n",
        "\n",
        "    # Update tracker with frame and appearance embeddings\n",
        "    tracks = tracker.update_tracks(raw_detections=boxes, embeds=features, frame=frame)\n",
        "\n",
        "    # Draw bounding boxes and IDs\n",
        "    for track in tracks:\n",
        "        if track.is_confirmed() and track.time_since_update <= 1:\n",
        "            box = track.to_tlbr()  # Get bounding box in format [x1, y1, x2, y2]\n",
        "            track_id = track.track_id  # Get track ID\n",
        "\n",
        "            # Initialize unique_id for each track\n",
        "            unique_id = None\n",
        "            current_class = None  # Initialize current_class before use\n",
        "\n",
        "            if track_id not in id_map:\n",
        "                # Assign a new unique ID based on class type\n",
        "                for detection in boxes:\n",
        "                    detection_box = detection[0]\n",
        "                    if (detection_box[0] <= box[0] <= detection_box[0] + detection_box[2] and\n",
        "                        detection_box[1] <= box[1] <= detection_box[1] + detection_box[3] and\n",
        "                        detection_box[0] <= box[2] <= detection_box[0] + detection_box[2] and\n",
        "                        detection_box[1] <= box[3] <= detection_box[1] + detection_box[3]):\n",
        "                        current_class = cls\n",
        "                        break\n",
        "\n",
        "                # Assign unique IDs based on the detected class\n",
        "                if current_class == 0:  # Child\n",
        "                    unique_id = child_unique_id\n",
        "                    id_map[track_id] = (child_unique_id, current_class)\n",
        "                    child_unique_id += 1\n",
        "                elif current_class == 1:  # Therapist\n",
        "                    unique_id = therapist_unique_id\n",
        "                    id_map[track_id] = (therapist_unique_id, current_class)\n",
        "                    therapist_unique_id += 1\n",
        "            else:\n",
        "                unique_id, current_class = id_map[track_id]\n",
        "\n",
        "            # Ensure unique_id is defined before using it\n",
        "            if unique_id is not None and current_class is not None:\n",
        "                # Draw bounding boxes and IDs\n",
        "                label = f\"ID {unique_id} {'Child' if current_class == 0 else 'Therapist'}\"\n",
        "                cv2.rectangle(frame, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (0, 255, 0), 2)\n",
        "                cv2.putText(frame, label, (int(box[0]), int(box[1])-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    # Write the frame to the output video\n",
        "    out.write(frame)\n",
        "\n",
        "# Release the video capture and writer\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7PW-pUgvlpt",
        "outputId": "86fb2c13-0d47-45b5-f2e8-71cea3c75de1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded imagenet pretrained weights from \"/root/.cache/torch/checkpoints/osnet_x0_25_imagenet.pth\"\n",
            "\n",
            "0: 384x640 2 Childs, 39.8ms\n",
            "Speed: 3.1ms preprocess, 39.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 31.8ms\n",
            "Speed: 3.3ms preprocess, 31.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 31.8ms\n",
            "Speed: 3.3ms preprocess, 31.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 31.8ms\n",
            "Speed: 3.4ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 31.7ms\n",
            "Speed: 3.2ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 31.8ms\n",
            "Speed: 3.2ms preprocess, 31.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 31.8ms\n",
            "Speed: 6.1ms preprocess, 31.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 31.7ms\n",
            "Speed: 3.1ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 31.8ms\n",
            "Speed: 3.2ms preprocess, 31.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 31.7ms\n",
            "Speed: 3.1ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 31.8ms\n",
            "Speed: 3.2ms preprocess, 31.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 31.7ms\n",
            "Speed: 2.9ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 31.7ms\n",
            "Speed: 3.1ms preprocess, 31.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.3ms\n",
            "Speed: 3.7ms preprocess, 34.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.1ms\n",
            "Speed: 5.1ms preprocess, 34.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.0ms\n",
            "Speed: 3.4ms preprocess, 34.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.3ms\n",
            "Speed: 3.2ms preprocess, 34.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.6ms\n",
            "Speed: 3.1ms preprocess, 34.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.2ms\n",
            "Speed: 3.4ms preprocess, 35.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.2ms\n",
            "Speed: 3.1ms preprocess, 35.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.6ms\n",
            "Speed: 3.2ms preprocess, 34.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.6ms\n",
            "Speed: 3.1ms preprocess, 34.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.4ms\n",
            "Speed: 3.0ms preprocess, 35.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.6ms\n",
            "Speed: 3.0ms preprocess, 34.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.6ms\n",
            "Speed: 3.1ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.6ms\n",
            "Speed: 3.3ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.6ms\n",
            "Speed: 3.2ms preprocess, 34.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.6ms\n",
            "Speed: 3.0ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.7ms\n",
            "Speed: 5.3ms preprocess, 34.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.6ms\n",
            "Speed: 3.0ms preprocess, 34.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.6ms\n",
            "Speed: 3.1ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 Adult, 2 Childs, 34.6ms\n",
            "Speed: 3.2ms preprocess, 34.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 Adult, 2 Childs, 34.6ms\n",
            "Speed: 3.6ms preprocess, 34.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 Adult, 2 Childs, 34.6ms\n",
            "Speed: 3.7ms preprocess, 34.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 Adult, 2 Childs, 36.7ms\n",
            "Speed: 4.4ms preprocess, 36.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 37.1ms\n",
            "Speed: 10.8ms preprocess, 37.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 37.4ms\n",
            "Speed: 3.3ms preprocess, 37.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 37.5ms\n",
            "Speed: 4.7ms preprocess, 37.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 37.4ms\n",
            "Speed: 3.6ms preprocess, 37.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 Adult, 2 Childs, 36.7ms\n",
            "Speed: 4.0ms preprocess, 36.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.6ms\n",
            "Speed: 3.0ms preprocess, 36.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.7ms\n",
            "Speed: 3.0ms preprocess, 36.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.7ms\n",
            "Speed: 3.0ms preprocess, 36.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.7ms\n",
            "Speed: 3.0ms preprocess, 36.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.7ms\n",
            "Speed: 3.5ms preprocess, 36.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.9ms\n",
            "Speed: 3.0ms preprocess, 35.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.2ms\n",
            "Speed: 3.0ms preprocess, 36.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.9ms\n",
            "Speed: 3.0ms preprocess, 35.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.0ms\n",
            "Speed: 3.4ms preprocess, 36.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.0ms\n",
            "Speed: 3.3ms preprocess, 36.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.0ms\n",
            "Speed: 3.1ms preprocess, 36.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.9ms\n",
            "Speed: 3.2ms preprocess, 35.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.0ms\n",
            "Speed: 3.3ms preprocess, 36.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 40.5ms\n",
            "Speed: 3.2ms preprocess, 40.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.0ms\n",
            "Speed: 3.1ms preprocess, 36.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.4ms\n",
            "Speed: 3.5ms preprocess, 36.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.0ms\n",
            "Speed: 4.2ms preprocess, 36.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 40.0ms\n",
            "Speed: 7.1ms preprocess, 40.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 39.9ms\n",
            "Speed: 5.8ms preprocess, 39.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 46.5ms\n",
            "Speed: 3.1ms preprocess, 46.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.7ms\n",
            "Speed: 9.2ms preprocess, 36.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 38.2ms\n",
            "Speed: 3.5ms preprocess, 38.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.8ms\n",
            "Speed: 3.0ms preprocess, 36.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 42.8ms\n",
            "Speed: 3.1ms preprocess, 42.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 38.1ms\n",
            "Speed: 5.5ms preprocess, 38.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 41.5ms\n",
            "Speed: 3.3ms preprocess, 41.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 39.4ms\n",
            "Speed: 3.6ms preprocess, 39.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 40.1ms\n",
            "Speed: 4.1ms preprocess, 40.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.7ms\n",
            "Speed: 3.6ms preprocess, 36.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.7ms\n",
            "Speed: 3.1ms preprocess, 36.7ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 40.5ms\n",
            "Speed: 3.3ms preprocess, 40.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 37.9ms\n",
            "Speed: 3.0ms preprocess, 37.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.7ms\n",
            "Speed: 3.1ms preprocess, 36.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 44.4ms\n",
            "Speed: 3.1ms preprocess, 44.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 39.9ms\n",
            "Speed: 3.1ms preprocess, 39.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 39.9ms\n",
            "Speed: 3.4ms preprocess, 39.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 41.0ms\n",
            "Speed: 3.1ms preprocess, 41.0ms inference, 9.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 39.9ms\n",
            "Speed: 3.5ms preprocess, 39.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 39.9ms\n",
            "Speed: 3.6ms preprocess, 39.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 39.9ms\n",
            "Speed: 3.2ms preprocess, 39.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.7ms\n",
            "Speed: 3.4ms preprocess, 36.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.6ms\n",
            "Speed: 3.4ms preprocess, 36.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 37.3ms\n",
            "Speed: 4.2ms preprocess, 37.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 41.0ms\n",
            "Speed: 2.8ms preprocess, 41.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.7ms\n",
            "Speed: 2.8ms preprocess, 36.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.7ms\n",
            "Speed: 2.7ms preprocess, 36.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.7ms\n",
            "Speed: 3.2ms preprocess, 36.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.7ms\n",
            "Speed: 3.1ms preprocess, 36.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.6ms\n",
            "Speed: 3.0ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.7ms\n",
            "Speed: 2.9ms preprocess, 34.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.6ms\n",
            "Speed: 4.9ms preprocess, 34.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.1ms\n",
            "Speed: 6.3ms preprocess, 35.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.6ms\n",
            "Speed: 2.9ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.6ms\n",
            "Speed: 3.0ms preprocess, 34.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.6ms\n",
            "Speed: 2.9ms preprocess, 34.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.6ms\n",
            "Speed: 2.8ms preprocess, 34.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.6ms\n",
            "Speed: 3.6ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.6ms\n",
            "Speed: 2.9ms preprocess, 34.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.6ms\n",
            "Speed: 3.3ms preprocess, 34.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.6ms\n",
            "Speed: 3.1ms preprocess, 34.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.6ms\n",
            "Speed: 3.1ms preprocess, 34.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.6ms\n",
            "Speed: 3.1ms preprocess, 34.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.6ms\n",
            "Speed: 3.1ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.0ms\n",
            "Speed: 3.3ms preprocess, 34.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.0ms\n",
            "Speed: 3.2ms preprocess, 34.0ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.0ms\n",
            "Speed: 2.9ms preprocess, 34.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.0ms\n",
            "Speed: 3.1ms preprocess, 34.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.0ms\n",
            "Speed: 3.0ms preprocess, 34.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.0ms\n",
            "Speed: 3.2ms preprocess, 34.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.0ms\n",
            "Speed: 9.8ms preprocess, 34.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.0ms\n",
            "Speed: 3.4ms preprocess, 34.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.0ms\n",
            "Speed: 7.4ms preprocess, 34.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 39.0ms\n",
            "Speed: 6.0ms preprocess, 39.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.8ms\n",
            "Speed: 3.4ms preprocess, 35.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.0ms\n",
            "Speed: 5.1ms preprocess, 34.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.2ms\n",
            "Speed: 6.5ms preprocess, 34.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.0ms\n",
            "Speed: 9.0ms preprocess, 34.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.6ms\n",
            "Speed: 3.0ms preprocess, 36.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.6ms\n",
            "Speed: 2.9ms preprocess, 36.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.9ms\n",
            "Speed: 3.1ms preprocess, 35.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 38.5ms\n",
            "Speed: 3.0ms preprocess, 38.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.2ms\n",
            "Speed: 3.0ms preprocess, 35.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.2ms\n",
            "Speed: 3.5ms preprocess, 35.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.3ms\n",
            "Speed: 6.9ms preprocess, 35.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.2ms\n",
            "Speed: 3.0ms preprocess, 35.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.3ms\n",
            "Speed: 3.1ms preprocess, 35.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.3ms\n",
            "Speed: 3.0ms preprocess, 35.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.4ms\n",
            "Speed: 3.0ms preprocess, 35.4ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.3ms\n",
            "Speed: 3.4ms preprocess, 35.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.2ms\n",
            "Speed: 2.9ms preprocess, 35.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.3ms\n",
            "Speed: 3.2ms preprocess, 35.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.3ms\n",
            "Speed: 3.1ms preprocess, 35.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.2ms\n",
            "Speed: 3.6ms preprocess, 35.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.3ms\n",
            "Speed: 3.3ms preprocess, 35.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.3ms\n",
            "Speed: 3.0ms preprocess, 35.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.3ms\n",
            "Speed: 3.3ms preprocess, 35.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.9ms\n",
            "Speed: 2.9ms preprocess, 35.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.9ms\n",
            "Speed: 3.2ms preprocess, 35.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.0ms\n",
            "Speed: 3.1ms preprocess, 36.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.7ms\n",
            "Speed: 3.8ms preprocess, 36.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.7ms\n",
            "Speed: 3.0ms preprocess, 36.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.2ms\n",
            "Speed: 2.9ms preprocess, 35.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.3ms\n",
            "Speed: 2.9ms preprocess, 35.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.8ms\n",
            "Speed: 2.9ms preprocess, 35.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.3ms\n",
            "Speed: 3.1ms preprocess, 35.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.3ms\n",
            "Speed: 2.9ms preprocess, 35.3ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.3ms\n",
            "Speed: 6.6ms preprocess, 35.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 Child, 35.2ms\n",
            "Speed: 3.0ms preprocess, 35.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 Child, 35.3ms\n",
            "Speed: 3.1ms preprocess, 35.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 Child, 35.3ms\n",
            "Speed: 3.0ms preprocess, 35.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 Child, 34.6ms\n",
            "Speed: 3.0ms preprocess, 34.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 Child, 34.7ms\n",
            "Speed: 3.3ms preprocess, 34.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 Child, 34.6ms\n",
            "Speed: 3.0ms preprocess, 34.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 Child, 34.6ms\n",
            "Speed: 3.1ms preprocess, 34.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 Child, 34.6ms\n",
            "Speed: 3.0ms preprocess, 34.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 Child, 35.0ms\n",
            "Speed: 2.9ms preprocess, 35.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 Child, 34.6ms\n",
            "Speed: 5.4ms preprocess, 34.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.6ms\n",
            "Speed: 3.1ms preprocess, 34.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 37.4ms\n",
            "Speed: 3.3ms preprocess, 37.4ms inference, 8.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 38.5ms\n",
            "Speed: 3.1ms preprocess, 38.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 34.6ms\n",
            "Speed: 5.0ms preprocess, 34.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 42.3ms\n",
            "Speed: 3.1ms preprocess, 42.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.6ms\n",
            "Speed: 5.0ms preprocess, 34.6ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 42.0ms\n",
            "Speed: 4.7ms preprocess, 42.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 46.3ms\n",
            "Speed: 2.7ms preprocess, 46.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 40.6ms\n",
            "Speed: 3.2ms preprocess, 40.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 39.9ms\n",
            "Speed: 3.6ms preprocess, 39.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 40.6ms\n",
            "Speed: 3.1ms preprocess, 40.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 Childs, 39.9ms\n",
            "Speed: 3.2ms preprocess, 39.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 39.9ms\n",
            "Speed: 11.1ms preprocess, 39.9ms inference, 8.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 44.9ms\n",
            "Speed: 3.1ms preprocess, 44.9ms inference, 8.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 42.7ms\n",
            "Speed: 2.9ms preprocess, 42.7ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 40.9ms\n",
            "Speed: 3.6ms preprocess, 40.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 50.5ms\n",
            "Speed: 3.4ms preprocess, 50.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 43.6ms\n",
            "Speed: 3.9ms preprocess, 43.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 39.9ms\n",
            "Speed: 3.9ms preprocess, 39.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 40.3ms\n",
            "Speed: 6.5ms preprocess, 40.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 42.9ms\n",
            "Speed: 3.5ms preprocess, 42.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 39.9ms\n",
            "Speed: 7.9ms preprocess, 39.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 39.9ms\n",
            "Speed: 2.8ms preprocess, 39.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 39.9ms\n",
            "Speed: 3.0ms preprocess, 39.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 36.7ms\n",
            "Speed: 3.0ms preprocess, 36.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 40.3ms\n",
            "Speed: 3.0ms preprocess, 40.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 36.7ms\n",
            "Speed: 2.9ms preprocess, 36.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.0ms\n",
            "Speed: 8.1ms preprocess, 36.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.0ms\n",
            "Speed: 3.3ms preprocess, 36.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.0ms\n",
            "Speed: 3.2ms preprocess, 36.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.0ms\n",
            "Speed: 3.8ms preprocess, 36.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.9ms\n",
            "Speed: 3.4ms preprocess, 35.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.0ms\n",
            "Speed: 3.5ms preprocess, 36.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.9ms\n",
            "Speed: 3.0ms preprocess, 35.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.0ms\n",
            "Speed: 3.0ms preprocess, 36.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.3ms\n",
            "Speed: 4.9ms preprocess, 36.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.3ms\n",
            "Speed: 3.7ms preprocess, 35.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.3ms\n",
            "Speed: 3.1ms preprocess, 35.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.3ms\n",
            "Speed: 3.1ms preprocess, 35.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.2ms\n",
            "Speed: 3.2ms preprocess, 35.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.4ms\n",
            "Speed: 4.3ms preprocess, 35.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.3ms\n",
            "Speed: 3.0ms preprocess, 35.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.2ms\n",
            "Speed: 2.9ms preprocess, 35.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.3ms\n",
            "Speed: 6.0ms preprocess, 35.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.3ms\n",
            "Speed: 3.0ms preprocess, 35.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.3ms\n",
            "Speed: 3.0ms preprocess, 35.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.2ms\n",
            "Speed: 4.0ms preprocess, 35.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 35.3ms\n",
            "Speed: 3.0ms preprocess, 35.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 35.3ms\n",
            "Speed: 3.1ms preprocess, 35.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.6ms\n",
            "Speed: 3.2ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.6ms\n",
            "Speed: 3.6ms preprocess, 34.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 34.6ms\n",
            "Speed: 3.7ms preprocess, 34.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 34.7ms\n",
            "Speed: 3.0ms preprocess, 34.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 34.6ms\n",
            "Speed: 3.0ms preprocess, 34.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 34.7ms\n",
            "Speed: 3.2ms preprocess, 34.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 34.6ms\n",
            "Speed: 4.1ms preprocess, 34.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 34.7ms\n",
            "Speed: 9.6ms preprocess, 34.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 34.6ms\n",
            "Speed: 3.0ms preprocess, 34.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 34.6ms\n",
            "Speed: 2.9ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 35.1ms\n",
            "Speed: 3.0ms preprocess, 35.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 39.6ms\n",
            "Speed: 3.1ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 38.0ms\n",
            "Speed: 3.7ms preprocess, 38.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 39.0ms\n",
            "Speed: 3.2ms preprocess, 39.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 36.7ms\n",
            "Speed: 2.7ms preprocess, 36.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 36.7ms\n",
            "Speed: 2.8ms preprocess, 36.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 36.7ms\n",
            "Speed: 3.3ms preprocess, 36.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 38.1ms\n",
            "Speed: 2.8ms preprocess, 38.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 40.4ms\n",
            "Speed: 3.9ms preprocess, 40.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 36.7ms\n",
            "Speed: 3.0ms preprocess, 36.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.6ms\n",
            "Speed: 3.6ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.6ms\n",
            "Speed: 3.0ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.7ms\n",
            "Speed: 3.2ms preprocess, 34.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 35.2ms\n",
            "Speed: 3.6ms preprocess, 35.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.7ms\n",
            "Speed: 6.7ms preprocess, 34.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 34.6ms\n",
            "Speed: 3.2ms preprocess, 34.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.3ms\n",
            "Speed: 6.3ms preprocess, 34.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 33.4ms\n",
            "Speed: 3.1ms preprocess, 33.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 33.4ms\n",
            "Speed: 3.0ms preprocess, 33.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 33.4ms\n",
            "Speed: 4.1ms preprocess, 33.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 33.4ms\n",
            "Speed: 3.1ms preprocess, 33.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 36.0ms\n",
            "Speed: 5.1ms preprocess, 36.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 33.4ms\n",
            "Speed: 3.5ms preprocess, 33.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 33.4ms\n",
            "Speed: 3.0ms preprocess, 33.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 33.4ms\n",
            "Speed: 3.2ms preprocess, 33.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 33.4ms\n",
            "Speed: 2.8ms preprocess, 33.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 33.4ms\n",
            "Speed: 2.9ms preprocess, 33.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 34.6ms\n",
            "Speed: 2.9ms preprocess, 34.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 33.4ms\n",
            "Speed: 4.2ms preprocess, 33.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 33.5ms\n",
            "Speed: 3.5ms preprocess, 33.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 35.3ms\n",
            "Speed: 2.9ms preprocess, 35.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 38.0ms\n",
            "Speed: 6.8ms preprocess, 38.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 41.9ms\n",
            "Speed: 4.3ms preprocess, 41.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 38.2ms\n",
            "Speed: 2.9ms preprocess, 38.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 37.4ms\n",
            "Speed: 3.2ms preprocess, 37.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 38.2ms\n",
            "Speed: 5.0ms preprocess, 38.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 39.0ms\n",
            "Speed: 3.1ms preprocess, 39.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 42.2ms\n",
            "Speed: 5.0ms preprocess, 42.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 40.2ms\n",
            "Speed: 2.9ms preprocess, 40.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 45.4ms\n",
            "Speed: 3.5ms preprocess, 45.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 39.9ms\n",
            "Speed: 3.3ms preprocess, 39.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 39.9ms\n",
            "Speed: 6.0ms preprocess, 39.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 Childs, 43.7ms\n",
            "Speed: 5.7ms preprocess, 43.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 40.2ms\n",
            "Speed: 3.1ms preprocess, 40.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 47.4ms\n",
            "Speed: 6.2ms preprocess, 47.4ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 42.2ms\n",
            "Speed: 3.3ms preprocess, 42.2ms inference, 8.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 43.4ms\n",
            "Speed: 3.4ms preprocess, 43.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 39.9ms\n",
            "Speed: 3.4ms preprocess, 39.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 39.9ms\n",
            "Speed: 4.2ms preprocess, 39.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 39.8ms\n",
            "Speed: 5.3ms preprocess, 39.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 49.5ms\n",
            "Speed: 3.7ms preprocess, 49.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 41.5ms\n",
            "Speed: 3.2ms preprocess, 41.5ms inference, 8.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 40.3ms\n",
            "Speed: 2.8ms preprocess, 40.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 Childs, 37.5ms\n",
            "Speed: 7.3ms preprocess, 37.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Strategies for Improvement\n",
        "\n",
        "1.Increase the Number of Training Epochs:\n",
        "\n",
        "Training the model for up to 100 epochs can help the model better learn the distinguishing features of children and therapists, leading to improved detection accuracy and more reliable tracking.\n",
        "2.Enhance Annotation Quality:\n",
        "\n",
        "Improving the quality and consistency of annotations will help the model learn more effectively, leading to better performance.\n",
        "3.Use Segmentation Instead of Detection:\n",
        "\n",
        "Adopting segmentation techniques can provide more precise class differentiation. Segmentation captures detailed object boundaries, which can enhance the model’s ability to distinguish between closely related classes, such as children and therapists."
      ],
      "metadata": {
        "id": "VcnCo3RGqg84"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.Troubleshooting and Considerations\n",
        "\n",
        "Common Issues\n",
        "\n",
        "Misidentification: Occurs due to low model accuracy.\n",
        "Tracking Inconsistencies: May result from misidentifications or overlapping detections.\n",
        "Suggested Fixes\n",
        "\n",
        "Increase Training Epochs: As mentioned above, extending the training period can improve accuracy.\n",
        "\n",
        "Improve Annotation Quality: Ensure high-quality and consistent labeling of training data.\n",
        "\n",
        "Consider Segmentation: For more precise object class differentiation."
      ],
      "metadata": {
        "id": "ycjHjvhXqmaZ"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}